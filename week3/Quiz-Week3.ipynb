{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz - Week 3B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Q1. \n",
    "* * * \n",
    "* Suppose we hash the elements of a set S having 20 members, to a bit array of length 99. The array is initially all-0's, and we set a bit to 1 whenever a member of S hashes to it. The hash function is random and uniform in its distribution. What is the expected fraction of 0's in the array after hashing? What is the expected fraction of 1's? You may assume that 99 is large enough that asymptotic limits are reached\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.\n",
    "* * *\n",
    "* Throwing Darts approximation - since we know that in this case we have t = 99, d = S*20, the fraction of 0's that remain will follow the following equation:\n",
    " \n",
    "\\begin{align}\n",
    "(1 - 1/t)^{t(d/t)} &~= e^{-d/t} \\\\\n",
    "&= e^{ \\frac{-20*S}{99} }\n",
    "\\end{align}\n",
    "\n",
    "* So in this cae, we can derive the fraction of 1's that remain will be $ 1 - e^{ \\frac{-20*S}{99} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "* * * \n",
    "* A certain Web mail service (like gmail, e.g.) has $10^8$ users, and wishes to create a sample of data about these users, **occupying $10^{10}$ bytes**. Activity at the service can be viewed as a **stream of elements**, each of which is an email. The element contains the ID of the sender, which must be one of the $10^8$ users of the service, and other information, e.g., the recipient(s), and contents of the message. The plan is to pick a **subset of the users** and collect in the $10^{10}$ bytes records of **length 100 bytes** about every email sent by the users in the selected set (and nothing about other users).\n",
    "* The method of Section 4.2.4 will be used. User ID's will be **hashed to a bucket number**, from 0 to 999,999. At all times, **there will be a threshold t** such that the 100-byte records for all the users whose ID's hash to **t or less** will be retained, and other users' records will not be retained. You may assume that each user generates emails at exactly the **same rate** as other users. **As a function of n**, the number of emails in the stream so far, **what should the threshold t be in order that the selected records will not exceed the $10^{10}$ bytes available to store records**? From the list below, identify the true statement about a value of n and its value of t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2. \n",
    "* * * \n",
    "* Since in this problem, basically we are going to partition the data stream by its value. Thus the relationship betwee n and t will be as folloing[note that hash value starts at 0]:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{t}{buckets\\#} = \\frac{10^{10}}{n} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz - Week 3A(Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. \n",
    "<pre>\n",
    "   C -- D -- E\n",
    " / |    |    | \\\n",
    "A  |    |    |  B\n",
    " \\ |    |    | /\n",
    "   F -- G -- H\n",
    "</pre>\n",
    "* * *\n",
    "\n",
    "Write the adjacency matrix A, the degree matrix D, and the Laplacian matrix L. For each, find the sum of all entries and the number of nonzero entries. Then identify the true statement from the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacent Matrix A:\n",
      "[[0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 1]\n",
      " [1 0 0 1 0 1 0 0]\n",
      " [0 0 1 0 1 0 1 0]\n",
      " [0 1 0 1 0 0 0 1]\n",
      " [1 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 1 0 1]\n",
      " [0 1 0 0 1 0 1 0]]\n",
      "Zero elements in A:\n",
      "42\n",
      "Sum as well as Non zero elements in A:\n",
      "22\n",
      "==========================================\n",
      "Degree Matrix D:\n",
      "[[2 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 3]]\n",
      "==========================================\n",
      "Laplacian Matrix L:\n",
      "[[ 2  0 -1  0  0 -1  0  0]\n",
      " [ 0  2  0  0 -1  0  0 -1]\n",
      " [-1  0  3 -1  0 -1  0  0]\n",
      " [ 0  0 -1  3 -1  0 -1  0]\n",
      " [ 0 -1  0 -1  3  0  0 -1]\n",
      " [-1  0 -1  0  0  3 -1  0]\n",
      " [ 0  0  0 -1  0 -1  3 -1]\n",
      " [ 0 -1  0  0 -1  0 -1  3]]\n"
     ]
    }
   ],
   "source": [
    "## Solution 1.\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, 0, 1, 0, 0, 1, 0, 0], #A\n",
    "              [0, 0, 0, 0, 1, 0, 0, 1], #B\n",
    "              [1, 0, 0, 1, 0, 1, 0, 0], #C\n",
    "              [0, 0, 1, 0, 1, 0, 1, 0], #D\n",
    "              [0, 1, 0, 1, 0, 0, 0, 1], #E\n",
    "              [1, 0, 1, 0, 0, 0, 1, 0], #F\n",
    "              [0, 0, 0, 1, 0, 1, 0, 1], #G\n",
    "              [0, 1, 0, 0, 1, 0, 1, 0]  #H\n",
    "             ])\n",
    "print \"Adjacent Matrix A:\"\n",
    "print A\n",
    "print \"Zero elements in A:\"\n",
    "print A.shape[1]* A.shape[0] - A.sum()\n",
    "print \"Sum as well as Non zero elements in A:\"\n",
    "print A.sum()\n",
    "print \"==========================================\"\n",
    "\n",
    "D = np.diag([2,2,3,3,3,3,3,3])\n",
    "print \"Degree Matrix D:\"\n",
    "print D\n",
    "\n",
    "print \"==========================================\"\n",
    "\n",
    "L = D - A\n",
    "\n",
    "print \"Laplacian Matrix L:\"\n",
    "print L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "* Given the following graph\n",
    "<pre>\n",
    "      2 -----6\n",
    "     /  \\    |\n",
    "    1    4   |\n",
    "     \\  /  \\ |\n",
    "      3      5\n",
    "</pre>\n",
    "* The goal is to find two clusters in this graph using Spectral Clustering on the Laplacian matrix. Compute the Laplacian of this graph. Then compute the **second eigen vector of the Laplacian** (the one corresponding to the second smallest eigenvalue).\n",
    "\n",
    "* To cluster the points, we decide to split at the mean value. We say that a node is a tie if its value in the eigen-vector is exactly equal to the mean value. Let's assume that if a point is a tie, we choose its cluster at random. Identify the true statement from the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Graph Laplacian Matrix: \n",
      "[[ 2 -1 -1  0  0  0]\n",
      " [-1  2  0 -1  0  0]\n",
      " [-1  0  2 -1  0  0]\n",
      " [ 0 -1 -1  3 -1  0]\n",
      " [ 0  0  0 -1  2 -1]\n",
      " [ 0 -1  0  0 -1  2]]\n",
      "Eigen values: \n",
      "[ 4.618  0.     1.     3.     2.382  2.   ]\n",
      "==========================================\n",
      "Eigen vectors: \n",
      "[[ 0.277  -0.4082 -0.3536  0.5774 -0.5804 -0.4082]\n",
      " [-0.3626 -0.4082 -0.1768 -0.2887  0.1108 -0.4082]\n",
      " [-0.3626 -0.4082 -0.1768 -0.2887  0.1108  0.4082]\n",
      " [ 0.6723 -0.4082  0.1768 -0.2887  0.538   0.4082]\n",
      " [-0.3626 -0.4082  0.7071  0.5774  0.1108  0.4082]\n",
      " [ 0.277  -0.4082  0.5303 -0.2887 -0.5804 -0.4082]]\n",
      "==========================================\n",
      "Second Smallest Eigen vectors: \n",
      "[-0.3536 -0.1768 -0.1768  0.1768  0.7071  0.5303]\n",
      "==========================================\n",
      "Mean of each row in vectors: \n",
      "0.117833333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, 1, 1, 0, 0, 0],\n",
    "              [1, 0, 0, 1, 0, 1],\n",
    "              [1, 0, 0, 1, 0, 0],\n",
    "              [0, 1, 1, 0, 1, 0],\n",
    "              [0, 0, 0, 1, 0, 1],\n",
    "              [0, 1, 0, 0, 1, 0]\n",
    "            ])\n",
    "\n",
    "D = np.diag([2, 3, 2, 3, 2, 2])\n",
    "L = (D - A)\n",
    "print \"==========================================\"\n",
    "print \"Graph Laplacian Matrix: \"\n",
    "print L\n",
    "values, vectors = np.linalg.eig(L)\n",
    "print \"Eigen values: \"\n",
    "values = np.around(values, decimals=4)\n",
    "print values\n",
    "print \"==========================================\"\n",
    "print \"Eigen vectors: \"\n",
    "vectors = np.around(vectors, decimals=4)\n",
    "print vectors\n",
    "print \"==========================================\"\n",
    "print \"Second Smallest Eigen vectors: \"\n",
    "print vectors[:, 2]\n",
    "print \"==========================================\"\n",
    "print \"Mean of each row in vectors: \"\n",
    "print np.mean(vectors[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "* We wish to estimate the surprise number (2nd moment) of a data stream, using the method of AMS. It happens that our stream consists of **ten different values**, which we'll call 1, 2,..., 10, that cycle repeatedly. That is, at timestamps 1 through 10, the element of the stream equals the timestamp, at timestamps 11 through 20, the element is the timestamp minus 10, and so on. **It is now timestamp 75**, and a 5 has just been read from the stream. As a start, you should calculate the surprise number for this time.\n",
    "\n",
    "* For our estimate of the surprise number, we shall choose **three timestamps at random**, and estimate the surprise number from each, using the AMS approach (length of the stream times 2m-1, where **m is the number of occurrences of the element of the stream at that timestamp**, considering all times from that timestamp on, to the current time). Then, our estimate will be the **median of the three resulting values**.\n",
    "\n",
    "* You should discover the simple rules that **determine the estimate** derived from any given timestamp and from any set of three timestamps. Then, identify from the list below the set of three \"random\" timestamps that **give the closest estimate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some hints:\n",
    "1. Be sure you have the surprise number correct. Notice that some of the elements appear 8 times and others appear 7 times. The surprise number is the sum over all elements that appear of the square of the number of times they appear.\n",
    "2. Remember that for any given timestamp, the estimate is the length of the stream (75 in this example) times 2m-1, where m is the number of times the element at that timestamp appears, at that time or later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565\n",
      "625.0\n",
      "725.0\n",
      "425.0\n",
      "525.0\n"
     ]
    }
   ],
   "source": [
    "def cal_supprise(current_t = 75):\n",
    "    common = ( current_t / 10 ) % 10\n",
    "    more_set = ( current_t ) % 10\n",
    "\n",
    "    less_set = 10 - more_set\n",
    "    \n",
    "    return more_set * (common+1)**2 + less_set * (common**2)\n",
    "    \n",
    "    \n",
    "\n",
    "def AMS(time_list, current_t = 75):\n",
    "    \n",
    "    estimates = []\n",
    "    for t in time_list:\n",
    "        delta = current_t - t\n",
    "        \n",
    "        elem = t % 10\n",
    "        threshold = current_t % 10\n",
    "        \n",
    "        common = (delta / 10) % 10\n",
    "\n",
    "        if elem > threshold:\n",
    "            estimates.append( ( 2*common - 1)*current_t )\n",
    "        else:\n",
    "            estimates.append( ( 2*common + 1)*current_t )\n",
    "\n",
    "    return estimates\n",
    "\n",
    "print cal_supprise()\n",
    "print np.mean(AMS([31,32,44]))\n",
    "print np.mean(AMS([14,35,42]))\n",
    "print np.mean(AMS([32,48,50]))\n",
    "print np.mean(AMS([22,42,62]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "* We wish to use the Flagolet-Martin lgorithm of Section 4.4 to count the number of distinct elements in a stream. Suppose that there are **ten possible elements, 1, 2,..., 10, that could appear in the stream**, but only four of them have actually appeared. To make our estimate of the count of distinct elements, we **hash each element to a 4-bit binary number**. The element x is hashed to 3x + 7 (modulo 11). For example, element 8 hashes to 3*8+7 = 31, which is 9 modulo 11 (i.e., the remainder of 31/11 is 9). Thus, the 4-bit string for element 8 is 1001.\n",
    "\n",
    "* A set of **four of the elements 1 through 10 could give an estimate that is exact** (if the estimate is 4), or too high, or too low. You should figure out under what circumstances a set of four elements falls into each of those categories. Then, identify in the list below the set of four elements that gives the exactly correct estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8\n",
      "4\n",
      "8\n",
      "=================\n",
      "2\n",
      "8\n",
      "2\n",
      "4\n",
      "=================\n",
      "2\n",
      "4\n",
      "8\n",
      "8\n",
      "=================\n",
      "8\n",
      "8\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def hash1(x):\n",
    "    return (3*x + 7) % 11\n",
    "\n",
    "def printBinary(x):\n",
    "    print \"- The binary result of {0} is:\".format(str(x)) + str(bin(x))\n",
    "\n",
    "def countTrailingZerosInBinary(num):\n",
    "    bnum = str(bin(num))\n",
    "    return len(bnum) - len(bnum.rstrip('0'))\n",
    "    \n",
    "def FlagoletMatrtin(hash_list):\n",
    "    maxnum = 0\n",
    "    for val in hash_list:\n",
    "        num = countTrailingZerosInBinary(val)\n",
    "        if num > maxnum:\n",
    "            maxnum = num\n",
    "    return 2**maxnum\n",
    "        \n",
    "        \n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,3,6,8]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [2,4,6,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [2,6,8,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [3,4,8,10]]))\n",
    "\n",
    "print \"=================\"\n",
    "\n",
    "print FlagoletMatrtin(([hash1(x) for x in [2,6,8,9]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [4,6,9,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,5,8,9]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,6,7,10]]))\n",
    "\n",
    "print \"=================\"\n",
    "\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,2,3,9]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,3,9,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [3,4,8,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [4,6,9,10]]))\n",
    "\n",
    "print \"=================\"\n",
    "\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,4,7,9]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [4,6,9,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [1,6,7,10]]))\n",
    "print FlagoletMatrtin(([hash1(x) for x in [4,5,6,10]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "* Suppose we are using the DGIM algorithm of Section 4.6.2 to estimate the number of 1's in suffixes of a sliding window of length 40. The current timestamp is 100, and we have the following buckets stored:\n",
    "\n",
    "<pre>\n",
    "    End Time    100  98  95  92  87  80  65\n",
    "        Size    1    1   2   2   4   8   8\n",
    "</pre>\n",
    "\n",
    "* **Note**: we are showing timestamps as absolute values, rather than modulo the window size, as DGIM would do.\n",
    "* Suppose that at times 101 through 105, 1's appear in the stream. Compute the set of buckets that would exist in the system at time 105. Then identify one such bucket from the list below. Buckets are represented by pairs (end-time, size).\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution5.\n",
    "<pre>\n",
    "step 1:\n",
    "    101 100 95 87 80 65\n",
    "    1   2   4  4  8  8\n",
    "step 2:\n",
    "    102 101 100 95 87 80 65\n",
    "    1   1   2   4  4  8  8\n",
    "step 3:\n",
    "    103 102 100 95 87 80 65\n",
    "    1   2   2   4  4  8  8\n",
    "step 4:\n",
    "    104 103 102 100 95 87 80 65\n",
    "    1   1   2   2   4  4  8  8\n",
    "step 5:\n",
    "    105 104 102 95 80\n",
    "    1   2   4   8  8 \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
