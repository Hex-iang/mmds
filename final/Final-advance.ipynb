{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question1. & Solution.\n",
    "\n",
    "* Suppose ABCD is __not a frequent itemset__, while ABC and ACD are __frequent itemsets__. Which of the following is definitely true?\n",
    "    * BC is a frequent itemset.\n",
    "        * __definitely true__\n",
    "    * ABCE is not a frequent itemset.\n",
    "        * non-informable\n",
    "    * ABCD is in the negative border.\n",
    "        * Which means that ABC, ACD, BCD, ABD are all frequent itemsets => non-informable\n",
    "    * ABD is a frequent itemset.\n",
    "        * non-informable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.\n",
    "* Suppose we are __representing sets__ by strings and __indexing the strings according to both the symbol and its position within the prefix__. We want to find strings within Jaccard distance at most 0.2 (i.e., similarity at least 0.8), and we are given __a probe string of length 24__. Into how many buckets must we look?\n",
    "\n",
    "## Solution.\n",
    "* we must look through floor( J * L + 1) = floor( 0.2 * 24 + 1) = floor( 4.8 + 1 ) = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 3.\n",
    "* In the following question we consider an example of __the implementation of the PCY algorithm__. All numbers should be treated as decimal; e.g., \"one million\" is 1,000,000, NOT $2^{20}$ = 1,048,576. All integers (item counts and bucket counts) require __4 bytes(32 bits)__.\n",
    "* We have __one billion bytes of main memory available for the first pass__. There are 100,000,000 items, and also 100,000,000 baskets, each of which contains exactly 10 items. Say that PCY is effective __if the average count of a bucket is at most half the support value__. For the given data, what is the smallest support value for which PCY will be effective?\n",
    "    * 6\n",
    "    * 60\n",
    "    * 600\n",
    "    * 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution.\n",
    "* I believe the order of magnitude will be 10 or 100, so I choose 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.\n",
    "* Suppose we want to represent the multiplication of two 10-by-10 matrices as a \"problem\" in the sense used for our discussion of __the theory of MapReduce algorithms__. How many pairs are in the input-output mapping?\n",
    "\n",
    "## Solution.\n",
    "* In a naive manner, a reducer get a triple ($A_i$, $B_j$, $C_{i,j}$). So in this case, the total number of pairs are 10 * 10 = 100 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 5.\n",
    "* The \"all-triples\" problem is described by __n inputs, (n choose 3) outputs__, and an input-output mapping where each output is connected to __a different set of three inputs__. \n",
    "* Suppose q is the __reducer size__. Which of the following functions of n and q approximates, to within a constant factor, __the lowest possible replication rate__ for a mapping schema that solves this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 6.\n",
    "* Suppose we are running the __DGIM algorithm__ (approximate counting of 1's in a window. At time t, the list of bucket sizes being maintained is 8,4,4,2,1,1. At times t+1, t+2, and t+3, 1's arrive on the input. Assuming no buckets are deleted because they fall outside the window, what are the numbers of buckets after each of the times t+1, t+2, and t+3?\n",
    "\n",
    "## Solution.\n",
    "* T + 1: 1, 2, 2, 4, 4, 8                        => 6 BUCKETS\n",
    "* T + 2: 1, 1, 2, 2, 4, 4, 8                     => 7 BUCKETS\n",
    "* T + 3: 1, 1, 1, 2, 2, 4, 4, 8 => 1, 2, 4, 8, 8 => 5 BUCKETS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7.\n",
    "* Apply the HITS algorithm to __a network with four pages (nodes) A, B, C, and D__, arranged in a chain:\n",
    "                                    A-->B-->C-->D\n",
    "\n",
    "* Compute the hubbiness and authority of each of these pages (scale doesn't matter, because you only have to identify pages with the same hubbiness or the same authority). Which of the following is FALSE.\n",
    "\n",
    "## Solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "[ 0.25  0.25  0.25  0.  ]\n",
      "[[0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n",
      "[ 0.    0.25  0.25  0.25]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, 0, 0, 0],\n",
    "              [1, 0, 0, 0],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 0, 1, 0]])\n",
    "\n",
    "mat1 = (A.T).dot(A)\n",
    "print mat1\n",
    "a = np.array([.25, .25, .25, .25])\n",
    "for i in xrange(3):\n",
    "    a = mat1.dot(a)\n",
    "\n",
    "print a\n",
    "\n",
    "mat2 = (A).dot(A.T)\n",
    "print mat2\n",
    "\n",
    "h = np.array([.25, .25, .25, .25])\n",
    "for i in xrange(3):\n",
    "    h = mat2.dot(h)\n",
    "print h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 8.\n",
    "* Let G be the __complete graph__ on five nodes (i.e., there is an edge in G between every pair of distinct nodes). What is the __sum of the squares__ of the elements of the Laplacian matrix for G?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,1,1,1],\n",
    "              [1,0,1,1,1],\n",
    "              [1,1,0,1,1],\n",
    "              [1,1,1,0,1],\n",
    "              [1,1,1,1,0]])\n",
    "\n",
    "D = np.array([[4,0,0,0,0],\n",
    "              [0,4,0,0,0],\n",
    "              [0,0,4,0,0],\n",
    "              [0,0,0,4,0],\n",
    "              [0,0,0,0,4]])\n",
    "L = D - A\n",
    "s = 0\n",
    "## output the sum of squares in laplacian matrix for G\n",
    "for row in L:\n",
    "    s += row.dot(row)\n",
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 9.\n",
    "* Note: This problem is similar to one on the Basic Final, but involves __a combiner__.\n",
    "* Consider the following MapReduce algorithm. The input is a collection of positive integers. Given integer X, the Map function produces a tuple with key Y and value X for each prime divisor Y of X. For example, if X = 20, there are two key-value pairs: (2,20) and (5,20). The Reduce function, given a key K and list L of values, produces a tuple with key K and value sum(L) i.e., the sum of the values in the list.\n",
    "\n",
    "* Suppose we process the input 9, 15, 16, 23, 25, 27, 28, 56, using a Combiner. There are 4 Map tasks and 1 Reduce task. The first Map task processes the first two inputs, the second the next two, and so on. How many input tuples does the Reduce task receive?\n",
    "\n",
    "## Solution.\n",
    "* Mapper procedure:\n",
    "    * Mapper 1:  9, 15\n",
    "        * {3, 9 | 15}, {5, 15}\n",
    "    * Mapper 2: 16, 23\n",
    "        * {2, 16}, {23, 23}\n",
    "    * Mapper 3: 25, 27\n",
    "        * {5, 25}, {3, 27}\n",
    "    * Mapper 4: 28, 56\n",
    "        * {2, 28 | 56}, {7, 28 | 56}\n",
    "\n",
    "* __So reducer will get 8 pairs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "* Consider an __AdWords scenario with 4 advertisers competing__ for the same query Q, all with the __same budget of 100 dollar__ and the same clickthrough rate. The table below shows the bid and the dollars spent by each advertiser until this point. Suppose we use Generalized BALANCE, and show one ad for each query. Which advertiser do we pick the next time query Q comes up?\n",
    "\n",
    "<pre>\n",
    "\n",
    "Advertiser\tBid\tSpend\n",
    "    A\t     $1\t$20\n",
    "    B\t     $2\t$40\n",
    "    C\t     $3\t$60\n",
    "    D\t     $4\t$80\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A's phi value = 0.550671035883\n",
      "B's phi value = 0.902376727812\n",
      "C's phi value = 0.989039861893\n",
      "D's phi value = 0.725076987688\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def phi(bid, spent, budget):\n",
    "    frac = 1 - float(spent) / budget\n",
    "    return bid * (1 - math.exp( - frac) )\n",
    "\n",
    "print \"A's phi value = {}\".format(phi(1, 20, 100))\n",
    "print \"B's phi value = {}\".format(phi(2, 40, 100))\n",
    "print \"C's phi value = {}\".format(phi(3, 60, 100))\n",
    "print \"D's phi value = {}\".format(phi(4, 80, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 11.\n",
    "* Suppose we wish to estimate the rating of __movie M by user U using item-Item Collaborative Filtering__, but there are no movies really similar to movie M. The average of all ratings is 3.5, user U's average rating is 3.1, and movie M's average rating is 4.3. What is our best guess for the rating of movie M by user U using a global baseline estimate?\n",
    "\n",
    "## Solution\n",
    "\n",
    "* best guess = (4.3 - 3.5) + 3.1 = 3.9\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 12\n",
    "* The table below shows data from ten people showing whether they like four different ice cream flavors. \n",
    "![alt image](desicion_tree_data.png)\n",
    "* Fit a __decision tree__ that predicts whether somebody would like Peanut ice cream based on whether she liked the other three flavors. Use __Information gain__ as the measure to make the splits. What is the order of splits?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "* Only chocolate is chosen, because there is no other splits improve imformation gain after this split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 13 & Solution\n",
    "* For an unknown graph with __3 nodes__, r1 is the topic sensitive PageRank using teleport set {0, 1} and r2 is is the topic sensitive PageRank using teleport set {1}. What’s __the value of the topic sensitive PageRank vector__ when using teleport set {0}?\n",
    "        * r1 - 2r2\n",
    "        * 2r1 - r2 √\n",
    "        * r2 - r1\n",
    "        * r1 - r2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 14\n",
    "* A is a __users times movie-ratings__ matrix like the one seen in class. Each column in A represents a movie, and there are 5 movies in total. Recall that a Singular Value Decomposition of a matrix is a multiplication of three matrices: U, Σ and V. is the following is such a decomposition for matrix A:\n",
    "\n",
    "![alt svd](SVD_small.png)\n",
    "\n",
    "* If we get __three new users__ with the following rating vectors: User 1: [5,0,0,0,0] User 2: [0,5,0,0,0] User 3: [0,0,0,0,4] If for advertising purposes we want to __cluster these three customers into two clusters using the movie concepts as features__. How would you cluster them? (use cosine distance).\n",
    "\n",
    "## Solution \n",
    "* cluster 1 => 1 & 3\n",
    "* cluster 2 => 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 15 & Solution\n",
    "* The soft margin SVM optimization problem is: \n",
    "\n",
    "* If for some i we have ξ=0, this indicates that the point xi is (check the true option):\n",
    "    * A support vector √\n",
    "    * Exactly in the decision boundary\n",
    "    * Incorrectly classified\n",
    "    * Correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
