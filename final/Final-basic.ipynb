{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Solution\n",
    "\n",
    "* 3-shingles for \"hello world\":\n",
    "    * hel, ell, llo, lo_, o_w ,_wo, wor, orl, rld => 9 in total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q2. Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "8.0\n",
      "0.0\n",
      "3.0\n",
      "6.0\n",
      "9.0\n",
      "1.0\n",
      "4.0\n",
      "7.0\n",
      "10.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "## Q2 Solution.\n",
    "def hash(x):\n",
    "    return math.fmod(3 * x + 2, 11)\n",
    "\n",
    "for i in xrange(1,12):\n",
    "    print hash(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "\n",
    "* This question involves three different __Bloom-filter-like__ scenarios. Each scenario involves setting to 1 certain bits of a 10-bit array, each bit of which is initially 0.\n",
    "\n",
    "* Scenario A: \n",
    "    * we use __one hash function__ that randomly, and with __equal probability__, selects one of the ten bits of the array. We apply this hash function to __four different inputs__ and set to 1 each of the selected bits.\n",
    "\n",
    "* Scenario B: \n",
    "    * We use __two hash functions__, each of which randomly, with equal probability, and independently of the other hash function __selects one of the of 10 bits of the array__. We apply both hash functions to each of __two inputs__ and set to 1 each of the selected bits.\n",
    "\n",
    "* Scenario C: \n",
    "    * We use __one hash function__ that randomly and with __equal probability__ selects two __different bits__ among the ten in the array. We apply this hash function to two inputs and set to 1 each of the selected bits.\n",
    "\n",
    "* Let a, b, and c be the expected number of bits set to 1 under scenarios A, B, and C, respectively. Which of the following correctly describes __the relationships among a, b, and c__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6561\n",
      "0.6561\n",
      "0.988888888889\n"
     ]
    }
   ],
   "source": [
    "## Q3 Solution.\n",
    "prob = 1.0 / 10\n",
    "a = (1 - prob)**4\n",
    "print a\n",
    "b = (1 - ( 1 - (1 - prob)**2) )**2\n",
    "print b\n",
    "c = (1 - (1.0 /10 * 1.0 / 9))\n",
    "print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.\n",
    "\n",
    "* In this __market-basket__ problem, there are __99 items__, numbered 2 to 100. There is a basket for __each prime number__ between 2 and 100. The basket for p contains all and only the items __whose numbers are a multiple of p__. For example, the basket for 17 contains the following items: {17, 34, 51, 68, 85}. What is the __support of the pair of items {12, 30}__?\n",
    "\n",
    "##Q4 Solution.\n",
    "\n",
    "support = 2 => {2,4,6,8, ...} & {3, 6, 9,...}\n",
    "\n",
    "## Q5.\n",
    "\n",
    "* To two decimal places, what is the cosine of the angle between the vectors [2,1,1] and [10,-7,1]?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466666666667\n"
     ]
    }
   ],
   "source": [
    "## Q5 Solution.\n",
    "vec1 = np.array([2,   1, 1])\n",
    "vec2 = np.array([10, -7, 1])\n",
    "print vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6.\n",
    "* In this question we use __six minhash functions__, organized as __three bands of two rows each__, to identify sets of high Jaccard similarity. If two sets have __Jaccard similarity 0.6__, what is the probability (to two decimal places) that this pair will become __a candidate pair__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262144\n"
     ]
    }
   ],
   "source": [
    "## Q6 Solution.\n",
    "\n",
    "# probability that they agree at one particular band\n",
    "p1 = 0.6**2\n",
    "print (1 - p1)**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7.\n",
    "* Suppose we have a __(.4, .6, .9, .1)-sensitive family of functions__. If we apply a 3-way OR construction to this family, we get a new family of functions whose sensitivity is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new LSH is (.4, .6, 0.999, 0.271)-sensitive family\n"
     ]
    }
   ],
   "source": [
    "## Q7 Solution.\n",
    "p1 = 1 - (1 - .9)**3\n",
    "p2 = 1 - (1 - .1)**3\n",
    "print \"new LSH is (.4, .6, {}, {})-sensitive family\".format(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8.\n",
    "\n",
    "* Suppose we have a database of (Class, Student, Grade) facts, each __giving the grade the student got in the class__. We want to estimate the fraction of students who have gotten A's in __at least 10 classes__, but we do not want to examine the entire relation, just a sample of __10% of the tuples.__ We shall hash tuples to 10 buckets, and take only those tuples in the first bucket. But to get a valid estimate of the fraction of students with at least 10 A's, we need to __pick our hash key judiciously__. To which Attribute(s) of the relation should we apply the hash function?\n",
    "\n",
    "## Q8 Solution.\n",
    "\n",
    "* We will need to hash it to with regard to class and students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q9\n",
    "\n",
    "* Suppose the Web consists of four pages A, B, C, and D, that form a chain\n",
    "    A-->B-->C-->D\n",
    "\n",
    "* We wish to compute the __PageRank of each of these pages__, but since D is a \"dead end,\" we will \"teleport\" from D with probability 1 to one of the four pages, each with __equal probability__. We do not teleport from pages A, B, or C. Assuming the sum of the PageRanks of the four pages is 1, what is the __PageRank of page B__, correct to two decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10000018  0.20000019  0.29999981  0.39999982]\n"
     ]
    }
   ],
   "source": [
    "## Q9 Solution.\n",
    "M = np.array([[0, 0, 0, .25],\n",
    "              [1, 0, 0, .25],\n",
    "              [0, 1, 0, .25],\n",
    "              [0, 0, 1, .25]])\n",
    "r = np.array([.25, .25, .25, .25])\n",
    "\n",
    "for i in xrange(30):\n",
    "    r = M.dot(r)\n",
    "\n",
    "print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q10.\n",
    "\n",
    "* Suppose in the __AGM model__ we have four individuals (A,B,C,D} and two communities. __Community 1__ consists of {A,B,C} and __Community 2__ consists of {B,C,D}. For Community 1 there is __a 30% chance__- it will cause an edge between any two of its members. For Community 2 there is __a 40% chance__ it will cause an edge between any two of its members. To the nearest two decimal places, what is the probability that __there is an edge between B and C__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n"
     ]
    }
   ],
   "source": [
    "## Q10 Solution.\n",
    "print 1 - (1 - .3)*(1 - .4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11.\n",
    "\n",
    "* X is a dataset of n columns for which we train a __supervised Machine Learning algorithm__. e is the error of the model measured against a __validation dataset__. Unfortunately, e is too high because model has __overfitted on the training data X__ and it doesn't generalize well. We now decide to reduce the model variance by reducing the dimensionality of X, using a __Singular Value Decomposition__, and using the resulting dataset to train our model. If i is __the number of singular values__ used in the SVD reduction, how does e change as a function of i, for i âˆˆ {1, 2,...,n}?\n",
    "\n",
    "## Solution.\n",
    "\n",
    "* A Convex Function starts low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25 -0.05]\n",
      " [-0.5  -0.1 ]\n",
      " [-0.76 -0.15]\n",
      " [-0.29  0.2 ]\n",
      " [-0.03  0.26]\n",
      " [-0.07  0.51]\n",
      " [-0.01  0.77]]\n",
      "[[ 6.74  0.  ]\n",
      " [ 0.    5.44]]\n",
      "[[-0.57 -0.11 -0.57 -0.11 -0.57]\n",
      " [-0.09  0.7  -0.09  0.7  -0.09]]\n",
      "[[ 0.98493  -0.00505   0.98493  -0.00505   0.98493 ]\n",
      " [ 1.96986  -0.0101    1.96986  -0.0101    1.96986 ]\n",
      " [ 2.993208 -0.007736  2.993208 -0.007736  2.993208]\n",
      " [ 1.016202  0.976606  1.016202  0.976606  1.016202]\n",
      " [-0.012042  1.012322 -0.012042  1.012322 -0.012042]\n",
      " [ 0.01923   1.993978  0.01923   1.993978  0.01923 ]\n",
      " [-0.338574  2.939574 -0.338574  2.939574 -0.338574]]\n"
     ]
    }
   ],
   "source": [
    "##Q12\n",
    "L = np.array([[-.25, -.5, -.76, -.29, -.03, -.07, -.01],\n",
    "              [-.05, -.1, -.15,  .20,  .26,  .51,  .77 ]]).T\n",
    "print L\n",
    "\n",
    "V = np.array([[6.74, 0],[0, 5.44]])\n",
    "print V\n",
    "\n",
    "R = np.array([[-.57, -.11, -.57, -.11, -.57],\n",
    "              [-.09, 0.70, -.09,  .7,  -.09]])\n",
    "print R\n",
    "print L.dot(V).dot(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13.\n",
    "* Recall that the power iteration does r=XÂ·r until converging, where X is a nxn matrix and n is the number of nodes in the graph. \n",
    "\n",
    "* Using the power iteration notation above, what is matrix X value when solving topic sensitive Pagerank with teleport set {0,1} for the following graph? __Use beta=0.8__. (Recall that the teleport set contains the destination nodes used when teleporting). \n",
    "![alt text](small_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36666667  0.1         0.1       ]\n",
      " [ 0.36666667  0.1         0.1       ]\n",
      " [ 0.26666667  0.8         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X  = 0.8 * np.array([[1.0/3, 0, 0],\n",
    "                     [1.0/3, 0, 0],\n",
    "                     [1.0/3, 1, 0]])\n",
    "X += 0.2 * np.array([[.5, .5, .5],\n",
    "                     [.5, .5, .5],\n",
    "                     [ 0,  0,  0]])\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14.\n",
    "\n",
    "* Here are two sets of integers S = {1,2,3,4} and T = {1,2,5,6,x}, where __x stands for some integer__. For how many different integer values of x are the __Jaccard similarity and the Jaccard distance of S and T the same__? (Note: x can be one of 1, 2, 5, or 6, but in that case T, being a set, will contain x only once and thus have four members, not five.)\n",
    "\n",
    "## Solution.\n",
    "* x = 3 or x = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q15.\n",
    "* Which of the following are advantages of using decision trees? (check all correct options)\n",
    "\n",
    "##  Solution.\n",
    "* My Answer\n",
    "    * It can handle categorical input data without any special preprocessing\n",
    "    * The resulting model is easy to interpret\n",
    "    * The training is easy to parallelize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q16.\n",
    "\n",
    "* Consider a dataset of points xi,....xn with labels yi,....,yi âˆˆ {-1, 1}, such that the data is separable. We run a soft-margin SVM and a hard-margin SVM, and in each case we obtain parameters w and b. Check the option that is true:\n",
    "    * The resulting w and b can be different, and the boundaries can be different.\n",
    "    * The resulting w and b are the same in the two cases, hence boundaries are the same.\n",
    "    * The resulting w and b can be different in the two cases, but the boundaries are the same.\n",
    "    * None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17.\n",
    "\n",
    "* Consider the following __MapReduce algorithm__. The input is a collection of positive integers. Given integer X, the Map function __produces a tuple with key Y and value X for each prime divisor Y of X__. For example, if X = 20, there are two key-value pairs: (2,20) and (5,20). The Reduce function, given a key K and list L of values, produces a tuple with key K and value sum(L) i.e., the sum of the values in the list. __Given the input 9, 15, 16, 23, 25, 27, 28, 56 which of the following tuples appears in the final output?__\n",
    "\n",
    "## Solution.\n",
    "\n",
    "* {2, 16 + 28 + 56 } => {2, 100}\n",
    "* {3,  9 + 15 + 27 } => {3, 51}\n",
    "* {5, 15 + 25}       => {5, 40}\n",
    "* {7, 28 + 56}       => {7, 84}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q18.\n",
    "* Suppose we run __K-means clustering__ over the following set of points in 2-d space using the __L1 distance metric__: \n",
    "    * (1,1), (2,1) (2,2), (3,3), (4,2), (2,4), (4,4). \n",
    "    * We pick k=2 and the initial centroids are (1,1) and (4,4). \n",
    "    * Which of these is the centroid of the cluster containing the point (3,3) when the algorithm terminates? \n",
    "\n",
    "* Recall that the L1 distance between two points is the __sum of their distances along each dimension__, \n",
    "    * e.g. the L1 distance between (1, 2) and (-1, 3) is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type other than float or double not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5eb3806dc379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     for point in points:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/scipy/cluster/vq.pyc\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(obs, k_or_guess, iter, thresh)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# the initial code book is randomly selected from observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mbest_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/scipy/cluster/vq.pyc\u001b[0m in \u001b[0;36m_kmeans\u001b[0;34m(obs, guess, thresh)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# recalc code_book as centroids of associated obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mcode_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_members\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cluster_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0mcode_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_book\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhas_members\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_dist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscipy/cluster/_vq.pyx\u001b[0m in \u001b[0;36mscipy.cluster._vq.update_cluster_means (scipy/cluster/_vq.c:4539)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: type other than float or double not supported"
     ]
    }
   ],
   "source": [
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "def L1(p1, p2):\n",
    "    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n",
    "\n",
    "c1 = [(1,1), (4,4)]\n",
    "points = np.array([[1, 1], [2, 1], [2, 2], [3, 3], [4, 2], [2, 4], [4, 4]]\n",
    ")\n",
    "# for point in points:\n",
    "#     minDist = 9999\n",
    "#     minIdx  = None\n",
    "#     for point in points:\n",
    "# print points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q20.\n",
    "\n",
    "* Consider an execution of the BALANCE algorithm with 4 advertisers, A1, A2, A3, A4, and 4 kinds of queries, Q1, Q2, Q3, Q4. \n",
    "    * Advertiser A1 bids on queries Q1 and Q2; \n",
    "    * A2 bids on queries Q2 and Q3; \n",
    "    * A3 on queries Q3 and Q4; \n",
    "    * and A4 on queries Q1 and Q4. \n",
    "    * All bids are equal to 1, and all clickthrough rates are equal. \n",
    "* All advertisers have a budget of 3, and ties are broken in favor of the advertiser with the lower index (e.g., A1 beats A2). Queries appear in the following order: \n",
    "                    Q1, Q2, Q3, Q3, Q1, Q2, Q3, Q1, Q4, Q1 \n",
    "\n",
    "* Which advertiserâ€™s budget is exhausted first?\n",
    "\n",
    "## Solution\n",
    "* A1 will exhausted first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q21.\n",
    "\n",
    "* Consider the bipartite graph with the following edges (you might want to draw a picture): \n",
    "            (a,1), (a,3), (b,1), (b,2), (b,4), (c,2), (d,1), (d,4) \n",
    "\n",
    "* Which of the following edges appears in __NO perfect matching__?\n",
    "\n",
    "## Solution\n",
    "\n",
    "* perfect match 1: a-3, b-4, c-2, d-1\n",
    "* perfect match 2: a-3, b-1, c-2, d-4\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q22.\n",
    "\n",
    "* The __Utility Matrix__ below captures the ratings of 5 users (A,B,C,D,E) for 5 movies (P,Q,R,S,T). Each known rating is a number between 1 and 5, and blanks represent unknown ratings. __What is the Pearson Correlation__ (also known as the Centered Cosine) between users B and D?\n",
    "<pre>\n",
    "    \tP\tQ\tR\tS\tT\n",
    "     A\t2\t\t4\t\t\n",
    "     B\t\t3\t1\t2\t\n",
    "     C\t5\t\t\t5\t\n",
    "     D\t\t4\t3\t\t2\n",
    "     E\t4\t\t\t5\t1\n",
    " \n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "vec1 = np.array([0, 1, -1, 0, 0])\n",
    "vec2 = np.array([0, 1,  0, 0, -1])\n",
    "print vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q23.\n",
    "\n",
    "* The Utility Matrix below captures the ratings of 5 users (A,B,C,D,E) for 5 movies (P,Q,R,S,T). Each known rating is a number between 1 and 5, and blanks represent unknown ratings. Let (U,M) denote the rating of movie M by user U. __We evaluate a Recommender System by withholding the ratings (A,P), (B,Q), and (C,S)__. The recommender system estimates (A,P)=1, (B,Q)=4, and (C,S)=5. What is the __RMSE__ of the Recommender System, rounded to 2 decimal places?\n",
    "<pre>\n",
    "\n",
    "        P\tQ\tR\tS\tT\n",
    "    A\t2\t\t4\t\t\n",
    "    B\t\t3\t1\t2\t\n",
    "    C\t5\t\t\t5\t\n",
    "    D\t\t4\t3\t\t2\n",
    "    E\t4\t\t\t5\t1\n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.816496580928\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "print \"RMSE = {}\".format(math.sqrt(2.0 / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q24.\n",
    "* We are going to perform a __hierarchical (agglomerative) clustering__ on the four strings {he, she, her, their}, using __edit distance__ (just insertions and deletions; no mutations of characters). \n",
    "    * Initially, each string is in a cluster by itself. \n",
    "    * The distance between two clusters is the minimum edit distance between two strings, __one chosen from each of the two clusters__.\n",
    "    * When we complete the __hierarchical clustering__, there is one cluster containing all four strings, and we performed three mergers of clusters to get to that point. \n",
    "    * For each of __the three mergers__ there was a distance between the merged clusters. What is the __sum of those three distances__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
